{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08377733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/codespace/team3_goodweather-1/1_DatasetCharacteristics/processed_data/combined_data_imputed.csv\n"
     ]
    }
   ],
   "source": [
    "# import of modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "# create dataframe using relative path\n",
    "input_path = \"../processed_data/combined_data_imputed.csv\"\n",
    "print(f\"Loading data from: {os.path.abspath(input_path)}\")\n",
    "df = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918748d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Warengruppe:\n",
      "[ 1.  3.  4.  5.  2.  6. nan]\n",
      "\n",
      "Number of unique categories: 6\n",
      "Value counts (including NaN):\n",
      "Warengruppe\n",
      "1.0    2174\n",
      "3.0    2174\n",
      "5.0    2174\n",
      "2.0    2174\n",
      "4.0    2120\n",
      "6.0     348\n",
      "NaN      47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in Warengruppe: 47\n",
      "\n",
      "New hot encoded columns added:\n",
      "['Warengruppe_1.0', 'Warengruppe_2.0', 'Warengruppe_3.0', 'Warengruppe_4.0', 'Warengruppe_5.0', 'Warengruppe_6.0', 'Warengruppe_nan']\n",
      "\n",
      "Sample of data with hot encoded Warengruppe variables (showing rows with valid Warengruppe):\n",
      "   Warengruppe  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0          1.0                1                0                0   \n",
      "1          3.0                0                0                1   \n",
      "2          4.0                0                0                0   \n",
      "3          5.0                0                0                0   \n",
      "4          2.0                0                1                0   \n",
      "5          2.0                0                1                0   \n",
      "6          5.0                0                0                0   \n",
      "7          3.0                0                0                1   \n",
      "8          4.0                0                0                0   \n",
      "9          1.0                1                0                0   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  Warengruppe_nan  \n",
      "0                0                0                0                0  \n",
      "1                0                0                0                0  \n",
      "2                1                0                0                0  \n",
      "3                0                1                0                0  \n",
      "4                0                0                0                0  \n",
      "5                0                0                0                0  \n",
      "6                0                1                0                0  \n",
      "7                0                0                0                0  \n",
      "8                1                0                0                0  \n",
      "9                0                0                0                0  \n",
      "\n",
      "Summary of hot encoded variables:\n",
      "Warengruppe_1.0: 2174 ones (1s)\n",
      "Warengruppe_2.0: 2174 ones (1s)\n",
      "Warengruppe_3.0: 2174 ones (1s)\n",
      "Warengruppe_4.0: 2120 ones (1s)\n",
      "Warengruppe_5.0: 2174 ones (1s)\n",
      "Warengruppe_6.0: 348 ones (1s)\n",
      "Warengruppe_nan: 47 ones (1s)\n"
     ]
    }
   ],
   "source": [
    "# Hot encode the variable Warengruppe\n",
    "\n",
    "# First, let's check the unique values in Warengruppe\n",
    "print(\"Unique values in Warengruppe:\")\n",
    "print(df['Warengruppe'].unique())\n",
    "print(f\"\\nNumber of unique categories: {df['Warengruppe'].nunique()}\")\n",
    "print(f\"Value counts (including NaN):\\n{df['Warengruppe'].value_counts(dropna=False)}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = df['Warengruppe'].isna().sum()\n",
    "print(f\"\\nMissing values in Warengruppe: {missing_count}\")\n",
    "\n",
    "# Create hot encoded (dummy) variables for Warengruppe\n",
    "# Using dummy_na=True to create a column for missing values as well\n",
    "# dtype=int ensures we get 1/0 instead of True/False\n",
    "warengruppe_dummies = pd.get_dummies(df['Warengruppe'], prefix='Warengruppe', dummy_na=True, dtype=int)\n",
    "\n",
    "# Add the dummy variables to the dataframe\n",
    "df = pd.concat([df, warengruppe_dummies], axis=1)\n",
    "\n",
    "# Display the new columns\n",
    "print(f\"\\nNew hot encoded columns added:\")\n",
    "hot_encoded_cols = [col for col in df.columns if col.startswith('Warengruppe_')]\n",
    "print(hot_encoded_cols)\n",
    "\n",
    "# Show a sample of the data with hot encoded variables (including non-NaN values)\n",
    "print(f\"\\nSample of data with hot encoded Warengruppe variables (showing rows with valid Warengruppe):\")\n",
    "non_nan_sample = df[df['Warengruppe'].notna()][['Warengruppe'] + hot_encoded_cols].head(10)\n",
    "print(non_nan_sample)\n",
    "\n",
    "# Show summary of hot encoded columns\n",
    "print(f\"\\nSummary of hot encoded variables:\")\n",
    "for col in hot_encoded_cols:\n",
    "    ones_count = df[col].sum()\n",
    "    print(f\"{col}: {ones_count} ones (1s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f37b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday distribution:\n",
      "Monday: 1599 days (14.3%)\n",
      "Tuesday: 1608 days (14.3%)\n",
      "Wednesday: 1587 days (14.2%)\n",
      "Thursday: 1609 days (14.4%)\n",
      "Friday: 1585 days (14.1%)\n",
      "Saturday: 1608 days (14.3%)\n",
      "Sunday: 1615 days (14.4%)\n",
      "\n",
      "New weekday columns created:\n",
      "  - Weekday_Monday\n",
      "  - Weekday_Tuesday\n",
      "  - Weekday_Wednesday\n",
      "  - Weekday_Thursday\n",
      "  - Weekday_Friday\n",
      "  - Weekday_Saturday\n",
      "  - Weekday_Sunday\n",
      "\n",
      "Verification - Each row should sum to 1:\n",
      "All rows sum to 1: True\n",
      "Min sum: 1, Max sum: 1\n",
      "\n",
      "Sample of weekday hot encoding:\n",
      "       Datum  weekday  Weekday_Monday  Weekday_Tuesday  Weekday_Wednesday  \\\n",
      "0 2013-07-01        0               1                0                  0   \n",
      "1 2013-07-01        0               1                0                  0   \n",
      "2 2013-07-01        0               1                0                  0   \n",
      "3 2013-07-01        0               1                0                  0   \n",
      "4 2013-07-01        0               1                0                  0   \n",
      "5 2013-07-02        1               0                1                  0   \n",
      "6 2013-07-02        1               0                1                  0   \n",
      "7 2013-07-02        1               0                1                  0   \n",
      "8 2013-07-02        1               0                1                  0   \n",
      "9 2013-07-02        1               0                1                  0   \n",
      "\n",
      "   Weekday_Thursday  Weekday_Friday  Weekday_Saturday  Weekday_Sunday  \n",
      "0                 0               0                 0               0  \n",
      "1                 0               0                 0               0  \n",
      "2                 0               0                 0               0  \n",
      "3                 0               0                 0               0  \n",
      "4                 0               0                 0               0  \n",
      "5                 0               0                 0               0  \n",
      "6                 0               0                 0               0  \n",
      "7                 0               0                 0               0  \n",
      "8                 0               0                 0               0  \n",
      "9                 0               0                 0               0  \n"
     ]
    }
   ],
   "source": [
    "# Hot encode weekdays from the Datum column\n",
    "\n",
    "# Ensure Datum is in datetime format (it should already be from previous cells)\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "# Extract the day of week (0=Monday, 1=Tuesday, ..., 6=Sunday)\n",
    "df['weekday'] = df['Datum'].dt.dayofweek\n",
    "\n",
    "# Create hot encoded columns for each weekday\n",
    "# Monday = 0, Tuesday = 1, Wednesday = 2, Thursday = 3, Friday = 4, Saturday = 5, Sunday = 6\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "for i, day_name in enumerate(weekday_names):\n",
    "    df[f'Weekday_{day_name}'] = (df['weekday'] == i).astype(int)\n",
    "\n",
    "# Display the distribution of weekdays\n",
    "print(\"Weekday distribution:\")\n",
    "weekday_counts = df['weekday'].value_counts().sort_index()\n",
    "for i, day_name in enumerate(weekday_names):\n",
    "    count = weekday_counts.get(i, 0)\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{day_name}: {count} days ({percentage:.1f}%)\")\n",
    "\n",
    "# Show the new hot encoded columns\n",
    "weekday_columns = [f'Weekday_{day}' for day in weekday_names]\n",
    "print(f\"\\nNew weekday columns created:\")\n",
    "for col in weekday_columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Verify hot encoding (exactly one weekday should be 1 for each row)\n",
    "weekday_sum = df[weekday_columns].sum(axis=1)\n",
    "print(f\"\\nVerification - Each row should sum to 1:\")\n",
    "print(f\"All rows sum to 1: {(weekday_sum == 1).all()}\")\n",
    "print(f\"Min sum: {weekday_sum.min()}, Max sum: {weekday_sum.max()}\")\n",
    "\n",
    "# Show sample of the weekday hot encoding\n",
    "print(f\"\\nSample of weekday hot encoding:\")\n",
    "sample_cols = ['Datum', 'weekday'] + weekday_columns\n",
    "print(df[sample_cols].head(10))\n",
    "\n",
    "# Drop the temporary weekday column as we only need the hot encoded versions\n",
    "df = df.drop('weekday', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ad5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows with rolling average:\n",
      "       Datum  Temperatur  Temperatur_7day_rolling\n",
      "0 2013-07-01     17.8375                  17.8375\n",
      "1 2013-07-01     17.8375                  17.8375\n",
      "2 2013-07-01     17.8375                  17.8375\n",
      "3 2013-07-01     17.8375                  17.8375\n",
      "4 2013-07-01     17.8375                  17.8375\n",
      "5 2013-07-02     17.3125                  17.7500\n",
      "6 2013-07-02     17.3125                  17.6875\n",
      "7 2013-07-02     17.3125                  17.6125\n",
      "8 2013-07-02     17.3125                  17.5375\n",
      "9 2013-07-02     17.3125                  17.4625\n",
      "\n",
      "Basic statistics for 7-day rolling average:\n",
      "count    11211.000000\n",
      "mean        12.035811\n",
      "std          7.086378\n",
      "min         -8.064286\n",
      "25%          6.301786\n",
      "50%         11.575000\n",
      "75%         17.926786\n",
      "max         31.379591\n",
      "Name: Temperatur_7day_rolling, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculation of 7-day rolling average for Temperature\n",
    "\n",
    "# Bringing 'Datum' in datetime format and sort by date\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df = df.sort_values('Datum')\n",
    "\n",
    "# Calculate rolling average over 7-day window for Temperature\n",
    "df['Temperatur_7day_rolling'] = df['Temperatur'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Display first few rows to verify the calculation\n",
    "print(\"First 10 rows with rolling average:\")\n",
    "print(df[['Datum', 'Temperatur', 'Temperatur_7day_rolling']].head(10))\n",
    "\n",
    "# Display basic statistics of the rolling average\n",
    "print(\"\\nBasic statistics for 7-day rolling average:\")\n",
    "print(df['Temperatur_7day_rolling'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37610ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niederschlag variable analysis:\n",
      "Data type: float64\n",
      "Basic statistics:\n",
      "count    11211.000000\n",
      "mean         2.041459\n",
      "std          4.037744\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.100000\n",
      "75%          2.200000\n",
      "max         37.700000\n",
      "Name: Niederschlag, dtype: float64\n",
      "\n",
      "Missing values: 0\n",
      "Number of zero values: 5314\n",
      "Number of positive values: 5897\n",
      "\n",
      "Categorization results:\n",
      "Niederschlag_trocken (dry days): 5314 days\n",
      "Niederschlag_nass (wet days): 5897 days\n",
      "Total rows: 11211\n",
      "Valid Niederschlag values: 11211\n",
      "Total categorized: 11211\n",
      "\n",
      "Sample of categorized data:\n",
      "       Datum  Niederschlag  Niederschlag_trocken  Niederschlag_nass\n",
      "0 2013-07-01           0.3                     0                  1\n",
      "1 2013-07-01           0.3                     0                  1\n",
      "2 2013-07-01           0.3                     0                  1\n",
      "3 2013-07-01           0.3                     0                  1\n",
      "4 2013-07-01           0.3                     0                  1\n",
      "5 2013-07-02           0.1                     0                  1\n",
      "6 2013-07-02           0.1                     0                  1\n",
      "7 2013-07-02           0.1                     0                  1\n",
      "8 2013-07-02           0.1                     0                  1\n",
      "9 2013-07-02           0.1                     0                  1\n",
      "\n",
      "Distribution of categories:\n",
      "Proportion of dry days: 0.474\n",
      "Proportion of wet days: 0.526\n"
     ]
    }
   ],
   "source": [
    "# Categorize Niederschlag variable into dry and wet categories\n",
    "\n",
    "# First, let's examine the Niederschlag variable\n",
    "print(\"Niederschlag variable analysis:\")\n",
    "print(f\"Data type: {df['Niederschlag'].dtype}\")\n",
    "print(f\"Basic statistics:\\n{df['Niederschlag'].describe()}\")\n",
    "print(f\"\\nMissing values: {df['Niederschlag'].isna().sum()}\")\n",
    "print(f\"Number of zero values: {(df['Niederschlag'] == 0).sum()}\")\n",
    "print(f\"Number of positive values: {(df['Niederschlag'] > 0).sum()}\")\n",
    "\n",
    "# Create hot encoded categories based on Niederschlag values\n",
    "# Niederschlag_trocken = 1 when Niederschlag = 0 (dry conditions)\n",
    "# Niederschlag_nass = 1 when Niederschlag > 0 (wet conditions)\n",
    "\n",
    "df['Niederschlag_trocken'] = (df['Niederschlag'] == 0).astype(int)\n",
    "df['Niederschlag_nass'] = (df['Niederschlag'] > 0).astype(int)\n",
    "\n",
    "# Verify the categorization\n",
    "print(f\"\\nCategorization results:\")\n",
    "print(f\"Niederschlag_trocken (dry days): {df['Niederschlag_trocken'].sum()} days\")\n",
    "print(f\"Niederschlag_nass (wet days): {df['Niederschlag_nass'].sum()} days\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "# Verify that the sum equals total rows (excluding NaN values if any)\n",
    "valid_niederschlag = df['Niederschlag'].notna().sum()\n",
    "total_categorized = df['Niederschlag_trocken'].sum() + df['Niederschlag_nass'].sum()\n",
    "print(f\"Valid Niederschlag values: {valid_niederschlag}\")\n",
    "print(f\"Total categorized: {total_categorized}\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nSample of categorized data:\")\n",
    "sample_cols = ['Datum', 'Niederschlag', 'Niederschlag_trocken', 'Niederschlag_nass']\n",
    "print(df[sample_cols].head(10))\n",
    "\n",
    "# Show distribution\n",
    "print(f\"\\nDistribution of categories:\")\n",
    "print(f\"Proportion of dry days: {df['Niederschlag_trocken'].mean():.3f}\")\n",
    "print(f\"Proportion of wet days: {df['Niederschlag_nass'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09101d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows with rolling average:\n",
      "       Datum  Niederschlag  Niederschlag_7day_rolling\n",
      "0 2013-07-01           0.3                   0.300000\n",
      "1 2013-07-01           0.3                   0.300000\n",
      "2 2013-07-01           0.3                   0.300000\n",
      "3 2013-07-01           0.3                   0.300000\n",
      "4 2013-07-01           0.3                   0.300000\n",
      "5 2013-07-02           0.1                   0.266667\n",
      "6 2013-07-02           0.1                   0.242857\n",
      "7 2013-07-02           0.1                   0.214286\n",
      "8 2013-07-02           0.1                   0.185714\n",
      "9 2013-07-02           0.1                   0.157143\n",
      "\n",
      "Basic statistics for 7-day rolling average:\n",
      "count    11211.000000\n",
      "mean         2.040442\n",
      "std          3.293091\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.600000\n",
      "75%          2.771429\n",
      "max         36.014286\n",
      "Name: Niederschlag_7day_rolling, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculation of 7-day rolling average for Niederschlag\n",
    "\n",
    "# Bringing 'Datum' in datetime format and sort by date\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "df = df.sort_values('Datum')\n",
    "\n",
    "# Calculate rolling average over 7-day window for Niederschlag\n",
    "df['Niederschlag_7day_rolling'] = df['Niederschlag'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Display first few rows to verify the calculation\n",
    "print(\"First 10 rows with rolling average:\")\n",
    "print(df[['Datum', 'Niederschlag', 'Niederschlag_7day_rolling']].head(10))\n",
    "\n",
    "# Display basic statistics of the rolling average\n",
    "print(\"\\nBasic statistics for 7-day rolling average:\")\n",
    "print(df['Niederschlag_7day_rolling'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499748f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis of 'Wettercode' Column ---\n",
      "Number of missing values: 0\n",
      "Percentage missing: 0.00%\n",
      "\n",
      "--- Summary Statistics ---\n",
      "count    11211.000000\n",
      "mean        35.432343\n",
      "std         27.121781\n",
      "min          0.000000\n",
      "25%         10.000000\n",
      "50%         21.000000\n",
      "75%         61.000000\n",
      "max         95.000000\n",
      "Name: Wettercode, dtype: float64\n",
      "\n",
      "--- Distribution of Codes (Top 10) ---\n",
      "Wettercode\n",
      "61.0    3578\n",
      "21.0    1804\n",
      "0.0     1510\n",
      "5.0     1041\n",
      "10.0     958\n",
      "63.0     768\n",
      "20.0     390\n",
      "95.0     203\n",
      "65.0     195\n",
      "22.0     142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#weathercode category encoding\n",
    "\n",
    "print(\"--- Analysis of 'Wettercode' Column ---\")\n",
    "\n",
    "# 1. Check for Missing Values\n",
    "# isnull() checks every row, and sum() counts how many are True.\n",
    "missing_count = df['Wettercode'].isnull().sum()\n",
    "print(f\"Number of missing values: {missing_count}\")\n",
    "\n",
    "# 2. Get the percentage of missing values\n",
    "# It is often helpful to know if the missing data is 1% or 50% of the dataset.\n",
    "missing_percentage = (missing_count / len(df)) * 100\n",
    "print(f\"Percentage missing: {missing_percentage:.2f}%\")\n",
    "\n",
    "# 3. Get a General Summary\n",
    "# .describe() is smart:\n",
    "# - If the column is Numbers: It gives mean, min, max, std.\n",
    "# - If the column is Text/Categories: It gives count, unique, top, frequency.\n",
    "print(\"\\n--- Summary Statistics ---\")\n",
    "print(df['Wettercode'].describe())\n",
    "\n",
    "# 4. Check the Distribution (Value Counts)\n",
    "# Since this is a \"Code\" (likely categories like 1=Sun, 2=Cloud), \n",
    "# value_counts() is usually more useful than mean/average.\n",
    "# dropna=False ensures we see the missing values in this list too.\n",
    "print(\"\\n--- Distribution of Codes (Top 10) ---\")\n",
    "print(df['Wettercode'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7047d73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Category Distribution ---\n",
      "Weather_Category\n",
      "6     4541\n",
      "4     2412\n",
      "1     1515\n",
      "3     1134\n",
      "2     1041\n",
      "8      236\n",
      "10     213\n",
      "7       60\n",
      "5       59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Sample Check ---\n",
      "      Wettercode  Weather_Category\n",
      "237         63.0                 6\n",
      "8760        71.0                 8\n",
      "4232         0.0                 1\n",
      "4095        61.0                 6\n",
      "6051        61.0                 6\n",
      "6752        61.0                 6\n",
      "5813        63.0                 6\n",
      "2156        61.0                 6\n",
      "3358        63.0                 6\n",
      "9909        10.0                 3\n"
     ]
    }
   ],
   "source": [
    "def categorize_wetter(code):\n",
    "    \"\"\"\n",
    "    Maps WMO codes (0-99) to 10 simplified categories.\n",
    "    Handles NaN values safely.\n",
    "    \"\"\"\n",
    "    if pd.isna(code):\n",
    "        return -1  # Indicate missing value with -1\n",
    "    \n",
    "    # Ensure code is an integer (in case it's stored as float 10.0 or string \"10\")\n",
    "    try:\n",
    "        c = int(code)\n",
    "    except ValueError:\n",
    "        return \"Invalid Format\"\n",
    "\n",
    "    # --- 1. Cloud / Stable ---\n",
    "    if 0 <= c <= 3:\n",
    "        return 1 \n",
    "\n",
    "    # --- 2. Haze / Dust / Sand ---\n",
    "    # 04-09 (Haze/Dust), 30-35 (Sandstorms)\n",
    "    elif (4 <= c <= 9) or (30 <= c <= 35):\n",
    "        return 2 \n",
    "\n",
    "    # --- 3. Fog / Mist ---\n",
    "    # 10-12 (Mist), 40-49 (Fog)\n",
    "    elif (10 <= c <= 12) or (40 <= c <= 49):\n",
    "        return 3\n",
    "\n",
    "    # --- 10. Thunderstorm (Checked early to catch special codes 17, 19, 29) ---\n",
    "    # 17 (Thunder audible), 19 (Tornado), 29 (Past Thunder), 91-99 (Current Thunder)\n",
    "    elif c in [17, 19, 29] or (91 <= c <= 99):\n",
    "        return 10\n",
    "\n",
    "    # --- 4. Past / Vicinity ---\n",
    "    # 13-16 (Vicinity), 18 (Squalls), 20-28 (Past Precip/Fog)\n",
    "    elif (13 <= c <= 18) or (20 <= c <= 28):\n",
    "        return 4\n",
    "\n",
    "    # --- 7. Freezing / Mix (Checked before Drizzle/Rain to catch freezing variants) ---\n",
    "    # 56-57 (Freezing Drizzle), 66-67 (Freezing Rain), 68-69 (Sleet)\n",
    "    elif c in [56, 57] or (66 <= c <= 69):\n",
    "        return 7\n",
    "\n",
    "    # --- 5. Drizzle ---\n",
    "    # 50-55, 58-59 (Remaining Drizzle codes)\n",
    "    elif 50 <= c <= 59:\n",
    "        return 5\n",
    "\n",
    "    # --- 6. Rain ---\n",
    "    # 60-65 (Rain)\n",
    "    elif 60 <= c <= 65:\n",
    "        return 6\n",
    "\n",
    "    # --- 8. Snow ---\n",
    "    # 36-39 (Drifting Snow), 70-79 (Snowfall)\n",
    "    elif (36 <= c <= 39) or (70 <= c <= 79):\n",
    "        return 8\n",
    "\n",
    "    # --- 9. Showers ---\n",
    "    # 80-90 (Rain, Snow, or Hail Showers)\n",
    "    elif 80 <= c <= 90:\n",
    "        return 9\n",
    "\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the function to create a new column\n",
    "# We use .apply() to run the function on every row\n",
    "df['Weather_Category'] = df['Wettercode'].apply(categorize_wetter)\n",
    "\n",
    "# --- Analysis of the new Categories ---\n",
    "\n",
    "print(\"--- New Category Distribution ---\")\n",
    "# Check how many rows fall into each of our 10 categories\n",
    "print(df['Weather_Category'].value_counts())\n",
    "\n",
    "print(\"\\n--- Sample Check ---\")\n",
    "# Show original code next to new category to verify\n",
    "print(df[['Wettercode', 'Weather_Category']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d0bd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- One-Hot Encoding Weather Categories ---\n",
      "Category -1 was missing in data. Creating empty column: W_Cat_-1\n",
      "Category 9 was missing in data. Creating empty column: W_Cat_9\n",
      "\n",
      "--- New Columns Created ---\n",
      "   W_Cat_-1  W_Cat_1  W_Cat_2  W_Cat_3  W_Cat_4  W_Cat_5  W_Cat_6  W_Cat_7  \\\n",
      "0         0        0        0        0        1        0        0        0   \n",
      "1         0        0        0        0        1        0        0        0   \n",
      "2         0        0        0        0        1        0        0        0   \n",
      "3         0        0        0        0        1        0        0        0   \n",
      "4         0        0        0        0        1        0        0        0   \n",
      "\n",
      "   W_Cat_8  W_Cat_9  W_Cat_10  \n",
      "0        0        0         0  \n",
      "1        0        0         0  \n",
      "2        0        0         0  \n",
      "3        0        0         0  \n",
      "4        0        0         0  \n",
      "\n",
      "--- Summary of Hot Encoding ---\n",
      "W_Cat_-1       0\n",
      "W_Cat_1     1515\n",
      "W_Cat_2     1041\n",
      "W_Cat_3     1134\n",
      "W_Cat_4     2412\n",
      "W_Cat_5       59\n",
      "W_Cat_6     4541\n",
      "W_Cat_7       60\n",
      "W_Cat_8      236\n",
      "W_Cat_9        0\n",
      "W_Cat_10     213\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding of the new Weather_Category_ID column\n",
    "\n",
    "print(\"--- One-Hot Encoding Weather Categories ---\")\n",
    "\n",
    "# 1. Perform One-Hot Encoding\n",
    "# columns=['Weather_Category']: Only encode this specific column\n",
    "# prefix='W_Cat': Adds this text to the new column names (e.g., W_Cat_1, W_Cat_2)\n",
    "# dtype=int: Ensures the result is 0 and 1 (not True/False)\n",
    "df_encoded = pd.get_dummies(df, columns=['Weather_Category'], prefix='W_Cat', dtype=int)\n",
    "\n",
    "# 2. Force all 11 columns to exist (Robustness Step)\n",
    "# If your specific dataset is missing a category (e.g., no \"Tornadoes\" happened),\n",
    "# get_dummies won't create a column for it. Machine Learning models often crash\n",
    "# if the number of columns changes. This block fixes that.\n",
    "\n",
    "expected_categories = [-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for cat in expected_categories:\n",
    "    col_name = f\"W_Cat_{cat}\"\n",
    "    if col_name not in df_encoded.columns:\n",
    "        print(f\"Category {cat} was missing in data. Creating empty column: {col_name}\")\n",
    "        df_encoded[col_name] = 0\n",
    "\n",
    "# 3. Reorder columns for neatness (Optional)\n",
    "# This sorts them so W_Cat_-1 comes first or last, and 1-10 are in order.\n",
    "encoded_cols = [f\"W_Cat_{cat}\" for cat in expected_categories]\n",
    "# We keep all original columns + the sorted encoded columns\n",
    "other_cols = [c for c in df_encoded.columns if c not in encoded_cols]\n",
    "df = df_encoded[other_cols + encoded_cols]\n",
    "\n",
    "# --- Verification ---\n",
    "\n",
    "print(\"\\n--- New Columns Created ---\")\n",
    "# Filter just to show the new columns\n",
    "weather_columns = [c for c in df.columns if 'W_Cat_' in c]\n",
    "print(df[weather_columns].head())\n",
    "\n",
    "print(\"\\n--- Summary of Hot Encoding ---\")\n",
    "# Check the sums to see how many 1s are in each column\n",
    "print(df[weather_columns].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49483c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly mean temperatures across entire dataset:\n",
      "Datum\n",
      "1      2.728366\n",
      "2      4.358531\n",
      "3      7.103450\n",
      "4     10.960906\n",
      "5     15.542939\n",
      "6     19.035405\n",
      "7     21.071860\n",
      "8     20.345694\n",
      "9     17.185659\n",
      "10    12.918950\n",
      "11     7.444665\n",
      "12     5.513308\n",
      "Name: Temperatur, dtype: float64\n",
      "\n",
      "Temperature categorization results:\n",
      "Cold days (Temperatur_kalt): 2092\n",
      "Normal days (Temperatur_normal): 6956\n",
      "Hot days (Temperatur_warm): 2163\n",
      "Total days: 11211\n",
      "\n",
      "Distribution of temperature categories:\n",
      "Cold: 2092 days (18.7%)\n",
      "Normal: 6956 days (62.0%)\n",
      "Hot: 2163 days (19.3%)\n",
      "\n",
      "Sample of data with new temperature features:\n",
      "   Temperatur_kalt  Temperatur_normal  Temperatur_warm\n",
      "0                1                  0                0\n",
      "1                1                  0                0\n",
      "2                1                  0                0\n",
      "3                1                  0                0\n",
      "4                1                  0                0\n",
      "5                1                  0                0\n",
      "6                1                  0                0\n",
      "7                1                  0                0\n",
      "8                1                  0                0\n",
      "9                1                  0                0\n",
      "\n",
      "Verification - Total hot-encoded values: 11211 (should equal 11211)\n"
     ]
    }
   ],
   "source": [
    "# Create hot encoded temperature categories based on monthly temperature averages\n",
    "\n",
    "# First, ensure we have the date in datetime format and extract month\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "\n",
    "# Calculate monthly mean temperature for the entire dataset\n",
    "monthly_temp_means = df.groupby(df['Datum'].dt.month)['Temperatur'].mean()\n",
    "print(\"Monthly mean temperatures across entire dataset:\")\n",
    "print(monthly_temp_means)\n",
    "\n",
    "# Create a mapping of month to mean temperature for easy lookup\n",
    "month_temp_dict = monthly_temp_means.to_dict()\n",
    "\n",
    "# Define thresholds for categorization (in degrees Celsius)\n",
    "# Cold: more than 3°C below monthly average\n",
    "# Normal: within ±3°C of monthly average  \n",
    "# Hot: more than 3°C above monthly average\n",
    "cold_threshold = -3.0\n",
    "hot_threshold = 3.0\n",
    "\n",
    "# Categorize temperature based on difference from monthly mean\n",
    "def categorize_temperature(row):\n",
    "    month = row['Datum'].month\n",
    "    monthly_mean = month_temp_dict[month]\n",
    "    temp_diff = row['Temperatur'] - monthly_mean\n",
    "    \n",
    "    if temp_diff <= cold_threshold:\n",
    "        return 'cold'\n",
    "    elif temp_diff >= hot_threshold:\n",
    "        return 'hot'\n",
    "    else:\n",
    "        return 'normal'\n",
    "\n",
    "# Apply categorization and create hot-encoded columns directly\n",
    "temp_categories = df.apply(categorize_temperature, axis=1)\n",
    "\n",
    "# Create hot-encoded columns for temperature categories\n",
    "df['Temperatur_kalt'] = (temp_categories == 'cold').astype(int)\n",
    "df['Temperatur_normal'] = (temp_categories == 'normal').astype(int)\n",
    "df['Temperatur_warm'] = (temp_categories == 'hot').astype(int)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTemperature categorization results:\")\n",
    "print(f\"Cold days (Temperatur_kalt): {df['Temperatur_kalt'].sum()}\")\n",
    "print(f\"Normal days (Temperatur_normal): {df['Temperatur_normal'].sum()}\")\n",
    "print(f\"Hot days (Temperatur_warm): {df['Temperatur_warm'].sum()}\")\n",
    "print(f\"Total days: {len(df)}\")\n",
    "\n",
    "# Show distribution by category\n",
    "print(f\"\\nDistribution of temperature categories:\")\n",
    "category_counts = temp_categories.value_counts()\n",
    "for category in ['cold', 'normal', 'hot']:\n",
    "    count = category_counts.get(category, 0)\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{category.capitalize()}: {count} days ({percentage:.1f}%)\")\n",
    "\n",
    "# Show sample data with new features\n",
    "print(f\"\\nSample of data with new temperature features:\")\n",
    "temp_cols = ['Temperatur_kalt', 'Temperatur_normal', 'Temperatur_warm']\n",
    "print(df[temp_cols].head(10))\n",
    "\n",
    "# Verify hot encoding (should sum to total number of rows)\n",
    "total_encoded = df['Temperatur_kalt'].sum() + df['Temperatur_normal'].sum() + df['Temperatur_warm'].sum()\n",
    "print(f\"\\nVerification - Total hot-encoded values: {total_encoded} (should equal {len(df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db62458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved successfully to: ../processed_data/combined_data_final_imputed.csv\n",
      "Full path: /home/codespace/team3_goodweather-1/1_DatasetCharacteristics/processed_data/combined_data_final_imputed.csv\n",
      "Shape of saved dataframe: (11211, 48)\n",
      "Columns in final dataframe: 48\n",
      "\n",
      "All new features added (15 total):\n",
      "Warengruppe features:\n",
      "  - Warengruppe_1.0\n",
      "  - Warengruppe_2.0\n",
      "  - Warengruppe_3.0\n",
      "  - Warengruppe_4.0\n",
      "  - Warengruppe_5.0\n",
      "  - Warengruppe_6.0\n",
      "  - Warengruppe_nan\n",
      "Niederschlag features:\n",
      "  - Niederschlag_trocken\n",
      "  - Niederschlag_nass\n",
      "  - Niederschlag_7day_rolling\n",
      "Temperature features:\n",
      "  - Temperatur_7day_rolling\n",
      "  - Temperatur_kalt\n",
      "  - Temperatur_normal\n",
      "  - Temperatur_warm\n",
      "Weather features:\n",
      "  - Weather_Category\n",
      "\n",
      "Preview of final dataframe:\n",
      "       Datum         id  Warengruppe      Umsatz  KielerWoche  Bewoelkung  \\\n",
      "0 2013-07-01  1307011.0          1.0  148.828353          0.0         6.0   \n",
      "1 2013-07-01  1307013.0          3.0  201.198426          0.0         6.0   \n",
      "2 2013-07-01  1307014.0          4.0   65.890169          0.0         6.0   \n",
      "3 2013-07-01  1307015.0          5.0  317.475875          0.0         6.0   \n",
      "4 2013-07-01  1307012.0          2.0  535.856285          0.0         6.0   \n",
      "\n",
      "   Temperatur  Windgeschwindigkeit  Wettercode  Niederschlag  ...  W_Cat_4  \\\n",
      "0     17.8375                 15.0        20.0           0.3  ...        1   \n",
      "1     17.8375                 15.0        20.0           0.3  ...        1   \n",
      "2     17.8375                 15.0        20.0           0.3  ...        1   \n",
      "3     17.8375                 15.0        20.0           0.3  ...        1   \n",
      "4     17.8375                 15.0        20.0           0.3  ...        1   \n",
      "\n",
      "   W_Cat_5  W_Cat_6  W_Cat_7  W_Cat_8  W_Cat_9  W_Cat_10  Temperatur_kalt  \\\n",
      "0        0        0        0        0        0         0                1   \n",
      "1        0        0        0        0        0         0                1   \n",
      "2        0        0        0        0        0         0                1   \n",
      "3        0        0        0        0        0         0                1   \n",
      "4        0        0        0        0        0         0                1   \n",
      "\n",
      "   Temperatur_normal  Temperatur_warm  \n",
      "0                  0                0  \n",
      "1                  0                0  \n",
      "2                  0                0  \n",
      "3                  0                0  \n",
      "4                  0                0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataframe with new features to CSV file\n",
    "\n",
    "# Define the output path (relative to notebooks directory)\n",
    "output_path = \"../processed_data/combined_data_final_imputed.csv\"\n",
    "\n",
    "# Save the dataframe with new features\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Verify the save was successful\n",
    "print(f\"Dataframe saved successfully to: {output_path}\")\n",
    "print(f\"Full path: {os.path.abspath(output_path)}\")\n",
    "print(f\"Shape of saved dataframe: {df.shape}\")\n",
    "print(f\"Columns in final dataframe: {len(df.columns)}\")\n",
    "\n",
    "# Display all the new feature columns that were added\n",
    "warengruppe_features = [col for col in df.columns if col.startswith('Warengruppe_')]\n",
    "niederschlag_features = ['Niederschlag_trocken', 'Niederschlag_nass', 'Niederschlag_7day_rolling']\n",
    "temperature_features = ['Temperatur_7day_rolling', 'Temperatur_kalt', 'Temperatur_normal', 'Temperatur_warm']\n",
    "weather_features = ['Weather_Category']\n",
    "\n",
    "all_new_features = warengruppe_features + niederschlag_features + temperature_features + weather_features\n",
    "\n",
    "print(f\"\\nAll new features added ({len(all_new_features)} total):\")\n",
    "print(\"Warengruppe features:\")\n",
    "for feature in warengruppe_features:\n",
    "    print(f\"  - {feature}\")\n",
    "print(\"Niederschlag features:\")\n",
    "for feature in niederschlag_features:\n",
    "    print(f\"  - {feature}\")\n",
    "print(\"Temperature features:\")\n",
    "for feature in temperature_features:\n",
    "    print(f\"  - {feature}\")\n",
    "print(\"Weather features:\")\n",
    "for feature in weather_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "# Show a preview of the final dataframe structure\n",
    "print(f\"\\nPreview of final dataframe:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
