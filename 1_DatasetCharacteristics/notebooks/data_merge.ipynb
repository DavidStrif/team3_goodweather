{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e91862",
   "metadata": {},
   "source": [
    "## Create new varible Holidays for Schleswig-Holstein\n",
    "### Add a variable to identify public holidays in Schleswig-Holstein for the dataset period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5117661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:49.729113Z",
     "iopub.status.busy": "2025-11-20T19:28:49.728615Z",
     "iopub.status.idle": "2025-11-20T19:28:51.838513Z",
     "shell.execute_reply": "2025-11-20T19:28:51.838196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 90 holidays for Schleswig-Holstein (2013-2018)\n",
      "Year distribution:\n",
      "  2013: 15 holidays\n",
      "  2014: 15 holidays\n",
      "  2015: 15 holidays\n",
      "  2016: 15 holidays\n",
      "  2017: 15 holidays\n",
      "  2018: 15 holidays\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Run the repository script that performs the merge (umsatz + test first),\n",
    "# then load and print a brief summary of the generated CSV.\n",
    "import subprocess, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "script = 'scripts/merge_datasets_fixed.py'\n",
    "print(f\"Running merge script: {script}\")\n",
    "res = subprocess.run([sys.executable, script], capture_output=True, text=True)\n",
    "print(res.stdout)\n",
    "if res.returncode != 0:\n",
    "    print('Merge script failed with return code', res.returncode)\n",
    "    print(res.stderr)\n",
    "else:\n",
    "    out = Path('combined_data_outer.csv')\n",
    "    if out.exists():\n",
    "        df = pd.read_csv(out, parse_dates=['Datum'])\n",
    "        print('Merged file loaded: rows=', len(df))\n",
    "        print('Date range:', df['Datum'].min(), 'to', df['Datum'].max())\n",
    "        print('Holidays:', df['is_holiday'].sum() if 'is_holiday' in df.columns else 'no column')\n",
    "    else:\n",
    "        print('Expected output file not found:', out)\n",
    "\n",
    "print(f\"Defined {len(schleswig_holstein_holidays)} holidays for Schleswig-Holstein (2013-2018)\")\n",
    "print(\"Year distribution:\")\n",
    "for year in years:\n",
    "    holidays_in_year = sum(1 for h in schleswig_holstein_holidays if h.year == year)\n",
    "    print(f\"  {year}: {holidays_in_year} holidays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1bf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db9990ef",
   "metadata": {},
   "source": [
    "### Create a function to add a holiday indicator to the merged dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5085cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.840218Z",
     "iopub.status.busy": "2025-11-20T19:28:51.840037Z",
     "iopub.status.idle": "2025-11-20T19:28:51.842745Z",
     "shell.execute_reply": "2025-11-20T19:28:51.842426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holiday indicator function defined successfully\n",
      "This function will add an 'is_holiday' column to the merged dataset\n"
     ]
    }
   ],
   "source": [
    "def add_holiday_indicator(df, holidays, date_column='Datum'):\n",
    "    \"\"\"\n",
    "    Add a holiday indicator column to a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to which the holiday indicator will be added\n",
    "    holidays : list\n",
    "        List of pd.Timestamp objects representing holidays\n",
    "    date_column : str\n",
    "        The name of the date column in the DataFrame (default: 'Datum')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new 'is_holiday' column (1 if holiday, 0 otherwise)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Create a boolean column checking if each date is in the holidays list\n",
    "    df['is_holiday'] = df[date_column].isin(holidays).astype(int)\n",
    "    return df\n",
    "\n",
    "print(\"Holiday indicator function defined successfully\")\n",
    "print(\"This function will add an 'is_holiday' column to the merged dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b433b",
   "metadata": {},
   "source": [
    "# This code merges the given CSV Datasets and can be used to combine new datasets to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a66ea",
   "metadata": {},
   "source": [
    "## Load and Merge Datasets (CAREFUL: This cell creats a new csv file)\n",
    "Now proceed with loading the CSV files and performing the outer join. The holiday indicator will be added after the merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384286d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.844489Z",
     "iopub.status.busy": "2025-11-20T19:28:51.844342Z",
     "iopub.status.idle": "2025-11-20T19:28:51.965640Z",
     "shell.execute_reply": "2025-11-20T19:28:51.965321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv...\n",
      "\n",
      "Error: File not found.\n",
      "Details: [Errno 2] No such file or directory: '1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv'\n",
      "Please make sure all CSV files are present in '1_DatasetCharacteristics/raw_data/'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Define File Names (repo-root-relative paths so nbconvert works) ---\n",
    "file_umsatz = '1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv'\n",
    "file_test = '1_DatasetCharacteristics/raw_data/test.csv'\n",
    "file_kiwo = '1_DatasetCharacteristics/raw_data/kiwo.csv'\n",
    "file_wetter = '1_DatasetCharacteristics/raw_data/wetter.csv'\n",
    "file_niederschlag = '1_DatasetCharacteristics/raw_data/Niederschlag.csv'\n",
    "\n",
    "try:\n",
    "    # --- 2. Load Umsatz and Test, then concatenate them ---\n",
    "    print(f\"Loading {file_umsatz}...\")\n",
    "    df_umsatz = pd.read_csv(file_umsatz, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_test}...\")\n",
    "    df_test = pd.read_csv(file_test, parse_dates=['Datum'])\n",
    "\n",
    "    # Concatenate Umsatz and test rows first (append test rows to umsatz)\n",
    "    df_umsatz_combined = pd.concat([df_umsatz, df_test], ignore_index=True)\n",
    "    print(f\"Combined umsatz + test: {len(df_umsatz_combined)} rows\")\n",
    "\n",
    "    # --- 3. Load other CSVs ---\n",
    "    print(f\"Loading {file_kiwo}...\")\n",
    "    df_kiwo = pd.read_csv(file_kiwo, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_wetter}...\")\n",
    "    df_wetter = pd.read_csv(file_wetter, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_niederschlag}...\")\n",
    "    df_niederschlag = pd.read_csv(file_niederschlag, parse_dates=['Datum'])\n",
    "\n",
    "    # --- 4. Set 'Datum' as the Index for All DataFrames ---\n",
    "    df_umsatz_combined = df_umsatz_combined.set_index('Datum')\n",
    "    df_kiwo = df_kiwo.set_index('Datum')\n",
    "    df_wetter = df_wetter.set_index('Datum')\n",
    "    df_niederschlag = df_niederschlag.set_index('Datum')\n",
    "\n",
    "    print(\"All files loaded and indexed on 'Datum'.\")\n",
    "\n",
    "    # --- 5. Perform the Outer Join ---\n",
    "    other_dfs = [df_kiwo, df_wetter, df_niederschlag]\n",
    "    print(\"Performing outer join with umsatz+test as base...\")\n",
    "    final_df = df_umsatz_combined.join(other_dfs, how='outer')\n",
    "\n",
    "    # --- 6. Clean Up and Add Holiday Indicator ---\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df = final_df.sort_values(by='Datum')\n",
    "    final_df = add_holiday_indicator(final_df, schleswig_holstein_holidays, date_column='Datum')\n",
    "    print(\"Added holiday indicator variable to merged dataset\")\n",
    "\n",
    "    # --- 7. Display Results and Save to File ---\n",
    "    print(\"\\n--- Join Complete ---\")\n",
    "    print(\"First 5 rows of the combined data:\")\n",
    "    print(final_df.head())\n",
    "\n",
    "    print(\"\\nLast 5 rows of the combined data:\")\n",
    "    print(final_df.tail())\n",
    "\n",
    "    print(f\"\\nTotal rows in combined file: {len(final_df)}\")\n",
    "    print(f\"Holidays found in dataset: {final_df['is_holiday'].sum()}\")\n",
    "\n",
    "    output_filename = 'combined_data_outer.csv'\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nSuccessfully saved combined data to '{output_filename}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: File not found.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    print(\"Please make sure all CSV files are present in '1_DatasetCharacteristics/raw_data/'.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8fd48",
   "metadata": {},
   "source": [
    "## Merge test.csv to the Dataset\n",
    "Append the test data to the merged dataset for extended coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3a939e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.967303Z",
     "iopub.status.busy": "2025-11-20T19:28:51.967168Z",
     "iopub.status.idle": "2025-11-20T19:28:51.979406Z",
     "shell.execute_reply": "2025-11-20T19:28:51.979076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged file 'combined_data_outer.csv'...\n",
      "Merged file loaded: 11782 rows\n",
      "Date range: 2012-01-01 00:00:00 to 2019-12-31 00:00:00\n",
      "Holidays in merged data: 294\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # The merged file was created in the previous cell: 'combined_data_outer.csv'\n",
    "    output_filename = 'combined_data_outer.csv'\n",
    "    print(f\"Loading merged file '{output_filename}'...\")\n",
    "    df_combined = pd.read_csv(output_filename, parse_dates=['Datum'])\n",
    "    print(f\"Merged file loaded: {len(df_combined)} rows\")\n",
    "    print(\"Date range:\", df_combined['Datum'].min(), \"to\", df_combined['Datum'].max())\n",
    "    if 'is_holiday' in df_combined.columns:\n",
    "        print(f\"Holidays in merged data: {df_combined['is_holiday'].sum()}\")\n",
    "    else:\n",
    "        print(\"Holiday indicator column not present in merged file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading merged file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
