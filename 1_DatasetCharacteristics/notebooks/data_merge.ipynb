{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e91862",
   "metadata": {},
   "source": [
    "## Create new varible Holidays for Schleswig-Holstein\n",
    "### Add a variable to identify public holidays in Schleswig-Holstein for the dataset period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5117661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 90 holidays for Schleswig-Holstein (2013-2017)\n",
      "Year distribution:\n",
      "  2013: 15 holidays\n",
      "  2014: 15 holidays\n",
      "  2015: 15 holidays\n",
      "  2016: 15 holidays\n",
      "  2017: 15 holidays\n",
      "  2018: 15 holidays\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Define Holidays for Schleswig-Holstein (2013-2018) ---\n",
    "# This creates a list of public holidays in Schleswig-Holstein for all years in the dataset\n",
    "# These dates are used to identify holidays in the dataset\n",
    "\n",
    "# Fixed holidays (same date every year)\n",
    "def get_fixed_holidays(years):\n",
    "    \"\"\"Generate fixed holidays for given years\"\"\"\n",
    "    fixed = []\n",
    "    for year in years:\n",
    "        fixed.extend([\n",
    "            pd.Timestamp(f'{year}-01-01'),  # New Year's Day\n",
    "            pd.Timestamp(f'{year}-05-01'),  # Labour Day\n",
    "            pd.Timestamp(f'{year}-10-03'),  # German Unity Day\n",
    "            pd.Timestamp(f'{year}-10-31'),  # Reformation Day\n",
    "            pd.Timestamp(f'{year}-11-01'),  # All Saints' Day\n",
    "            pd.Timestamp(f'{year}-12-25'),  # Christmas Day\n",
    "            pd.Timestamp(f'{year}-12-26'),  # Boxing Day\n",
    "        ])\n",
    "    return fixed\n",
    "\n",
    "# Easter-based holidays (moveable dates)\n",
    "# These are calculated based on Easter Sunday\n",
    "easter_dates = {\n",
    "    2013: pd.Timestamp('2013-03-31'),\n",
    "    2014: pd.Timestamp('2014-04-20'),\n",
    "    2015: pd.Timestamp('2015-04-05'),\n",
    "    2016: pd.Timestamp('2016-03-27'),\n",
    "    2017: pd.Timestamp('2017-04-16'),\n",
    "    2018: pd.Timestamp('2018-04-01'),\n",
    "}\n",
    "\n",
    "def get_easter_holidays(easter_dates):\n",
    "    \"\"\"Generate Easter-based holidays from Easter Sunday dates\"\"\"\n",
    "    easter_holidays = []\n",
    "    for year, easter in easter_dates.items():\n",
    "        # Good Friday (2 days before Easter)\n",
    "        easter_holidays.append(easter - pd.Timedelta(days=2))\n",
    "        # Easter Sunday\n",
    "        easter_holidays.append(easter)\n",
    "        # Easter Monday (1 day after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=1))\n",
    "        # Ascension Day (39 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=39))\n",
    "        # Whit Sunday (49 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=49))\n",
    "        # Whit Monday (50 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=50))\n",
    "        # Corpus Christi (60 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=60))\n",
    "    return easter_holidays\n",
    "\n",
    "# Carnival Tuesday (moveable, 47 days before Easter)\n",
    "carnival_dates = {\n",
    "    2013: pd.Timestamp('2013-02-12'),\n",
    "    2014: pd.Timestamp('2014-03-04'),\n",
    "    2015: pd.Timestamp('2015-02-17'),\n",
    "    2016: pd.Timestamp('2016-02-09'),\n",
    "    2017: pd.Timestamp('2017-02-28'),\n",
    "    2018: pd.Timestamp('2018-02-13'),\n",
    "}\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017, 2018]\n",
    "\n",
    "# Combine all holidays\n",
    "schleswig_holstein_holidays = (\n",
    "    get_fixed_holidays(years) + \n",
    "    get_easter_holidays(easter_dates) + \n",
    "    list(carnival_dates.values())\n",
    ")\n",
    "\n",
    "# Remove duplicates and sort\n",
    "schleswig_holstein_holidays = sorted(list(set(schleswig_holstein_holidays)))\n",
    "\n",
    "print(f\"Defined {len(schleswig_holstein_holidays)} holidays for Schleswig-Holstein (2013-2017)\")\n",
    "print(\"Year distribution:\")\n",
    "for year in years:\n",
    "    holidays_in_year = sum(1 for h in schleswig_holstein_holidays if h.year == year)\n",
    "    print(f\"  {year}: {holidays_in_year} holidays\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9990ef",
   "metadata": {},
   "source": [
    "### Create a function to add a holiday indicator to the merged dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5085cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holiday indicator function defined successfully\n",
      "This function will add an 'is_holiday' column to the merged dataset\n"
     ]
    }
   ],
   "source": [
    "def add_holiday_indicator(df, holidays, date_column='Datum'):\n",
    "    \"\"\"\n",
    "    Add a holiday indicator column to a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to which the holiday indicator will be added\n",
    "    holidays : list\n",
    "        List of pd.Timestamp objects representing holidays\n",
    "    date_column : str\n",
    "        The name of the date column in the DataFrame (default: 'Datum')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new 'is_holiday' column (1 if holiday, 0 otherwise)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Create a boolean column checking if each date is in the holidays list\n",
    "    df['is_holiday'] = df[date_column].isin(holidays).astype(int)\n",
    "    return df\n",
    "\n",
    "print(\"Holiday indicator function defined successfully\")\n",
    "print(\"This function will add an 'is_holiday' column to the merged dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b433b",
   "metadata": {},
   "source": [
    "# This code merges the given CSV Datasets and can be used to combine new datasets to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a66ea",
   "metadata": {},
   "source": [
    "## Load and Merge Datasets (CAREFUL: This cell creats a new csv file)\n",
    "Now proceed with loading the CSV files and performing the outer join. The holiday indicator will be added after the merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384286d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv...\n",
      "Loading /workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/kiwo.csv...\n",
      "Loading /workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/wetter.csv...\n",
      "Loading /workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/Niederschlag.csv...\n",
      "All files loaded and indexed on 'Datum'.\n",
      "Performing outer join...\n",
      "Added holiday indicator variable to merged dataset\n",
      "\n",
      "--- Join Complete ---\n",
      "First 5 rows of the combined data:\n",
      "       Datum  id  Warengruppe  Umsatz  KielerWoche  Bewoelkung  Temperatur  \\\n",
      "0 2012-01-01 NaN          NaN     NaN          NaN         8.0      9.8250   \n",
      "1 2012-01-02 NaN          NaN     NaN          NaN         7.0      7.4375   \n",
      "2 2012-01-03 NaN          NaN     NaN          NaN         8.0      5.5375   \n",
      "3 2012-01-04 NaN          NaN     NaN          NaN         4.0      5.6875   \n",
      "4 2012-01-05 NaN          NaN     NaN          NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  Niederschlag  is_holiday  \n",
      "0                 14.0        58.0          14.0           0  \n",
      "1                 12.0         NaN           0.0           0  \n",
      "2                 18.0        63.0          20.8           0  \n",
      "3                 19.0        80.0          19.7           0  \n",
      "4                 23.0        80.0           3.3           0  \n",
      "\n",
      "Last 5 rows of the combined data:\n",
      "           Datum  id  Warengruppe  Umsatz  KielerWoche  Bewoelkung  \\\n",
      "10302 2019-12-27 NaN          NaN     NaN          NaN         NaN   \n",
      "10303 2019-12-28 NaN          NaN     NaN          NaN         NaN   \n",
      "10304 2019-12-29 NaN          NaN     NaN          NaN         NaN   \n",
      "10305 2019-12-30 NaN          NaN     NaN          NaN         NaN   \n",
      "10306 2019-12-31 NaN          NaN     NaN          NaN         NaN   \n",
      "\n",
      "       Temperatur  Windgeschwindigkeit  Wettercode  Niederschlag  is_holiday  \n",
      "10302         NaN                  NaN         NaN           0.0           0  \n",
      "10303         NaN                  NaN         NaN           0.0           0  \n",
      "10304         NaN                  NaN         NaN           0.0           0  \n",
      "10305         NaN                  NaN         NaN           0.1           0  \n",
      "10306         NaN                  NaN         NaN           0.0           0  \n",
      "\n",
      "Total rows in combined file: 10307\n",
      "Holidays found in dataset: 285\n",
      "\n",
      "Successfully saved combined data to 'combined_data_outer.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "file_umsatz = '/workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv'\n",
    "file_kiwo = '/workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/kiwo.csv'\n",
    "file_wetter = '/workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/wetter.csv'\n",
    "file_niederschlag = '/workspaces/team3_goodweather/1_DatasetCharacteristics/raw_data/Niederschlag.csv'\n",
    "\n",
    "\n",
    "try:\n",
    "    # --- 2. Load CSVs and Parse 'Datum' Column ---\n",
    "    # We use parse_dates=['Datum'] to ensure Pandas treats \n",
    "    # the join column as a date, which is crucial for accuracy.\n",
    "    print(f\"Loading {file_umsatz}...\")\n",
    "    df_umsatz = pd.read_csv(file_umsatz, parse_dates=['Datum'])\n",
    "    \n",
    "    print(f\"Loading {file_kiwo}...\")\n",
    "    df_kiwo = pd.read_csv(file_kiwo, parse_dates=['Datum'])\n",
    "    \n",
    "    print(f\"Loading {file_wetter}...\")\n",
    "    df_wetter = pd.read_csv(file_wetter, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_niederschlag}...\")\n",
    "    df_niederschlag = pd.read_csv(file_niederschlag, parse_dates=['Datum'])\n",
    "\n",
    "    # --- 3. Set 'Datum' as the Index for All DataFrames ---\n",
    "    # Joining on the index is a very efficient way to combine DataFrames.\n",
    "    df_umsatz = df_umsatz.set_index('Datum')\n",
    "    df_kiwo = df_kiwo.set_index('Datum')\n",
    "    df_wetter = df_wetter.set_index('Datum')\n",
    "    df_niederschlag = df_niederschlag.set_index('Datum')\n",
    "    \n",
    "    print(\"All files loaded and indexed on 'Datum'.\")\n",
    "\n",
    "    # --- 4. Perform the Outer Join ---\n",
    "    # We start with the largest DataFrame (df_umsatz) and join the others to it.\n",
    "    # how='outer' is the key part: it includes all dates from all three files.\n",
    "    # If a date exists in one file but not another, the missing data\n",
    "    # will be filled with 'NaN' (Not a Number).\n",
    "    \n",
    "    # We can join a list of DataFrames at once.\n",
    "    other_dfs = [df_kiwo, df_wetter, df_niederschlag]\n",
    "    \n",
    "    print(\"Performing outer join...\")\n",
    "    final_df = df_umsatz.join(other_dfs, how='outer')\n",
    "\n",
    "    # --- 5. Clean Up and Add Holiday Indicator ---\n",
    "    \n",
    "    # After joining, 'Datum' is the index. Let's make it a regular column again.\n",
    "    final_df = final_df.reset_index()\n",
    "    \n",
    "    # You may want to sort by date to make the final file logical\n",
    "    final_df = final_df.sort_values(by='Datum')\n",
    "    \n",
    "    # Add the holiday indicator variable\n",
    "    final_df = add_holiday_indicator(final_df, schleswig_holstein_holidays, date_column='Datum')\n",
    "    print(\"Added holiday indicator variable to merged dataset\")\n",
    "\n",
    "    # --- 6. Display Results and Save to File ---\n",
    "    print(\"\\n--- Join Complete ---\")\n",
    "    print(\"First 5 rows of the combined data:\")\n",
    "    print(final_df.head())\n",
    "    \n",
    "    print(\"\\nLast 5 rows of the combined data:\")\n",
    "    print(final_df.tail())\n",
    "\n",
    "    print(f\"\\nTotal rows in combined file: {len(final_df)}\")\n",
    "    print(f\"Holidays found in dataset: {final_df['is_holiday'].sum()}\")\n",
    "    \n",
    "    # Save the final result to a new CSV\n",
    "    output_filename = 'combined_data_outer.csv'\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully saved combined data to '{output_filename}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: File not found.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    print(\"Please make sure all CSV files (umsatzdaten_gekuerzt.csv, kiwo.csv, wetter.csv, Niederschlag.csv) are in the same directory as the script.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
