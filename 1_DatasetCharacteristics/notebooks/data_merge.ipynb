{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e91862",
   "metadata": {},
   "source": [
    "## Create new varible Holidays for Schleswig-Holstein\n",
    "### Add a variable to identify public holidays in Schleswig-Holstein for the dataset period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5117661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:49.729113Z",
     "iopub.status.busy": "2025-11-20T19:28:49.728615Z",
     "iopub.status.idle": "2025-11-20T19:28:51.838513Z",
     "shell.execute_reply": "2025-11-20T19:28:51.838196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 90 holidays for Schleswig-Holstein (2013-2018)\n",
      "Year distribution:\n",
      "  2013: 15 holidays\n",
      "  2014: 15 holidays\n",
      "  2015: 15 holidays\n",
      "  2016: 15 holidays\n",
      "  2017: 15 holidays\n",
      "  2018: 15 holidays\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Define Holidays for Schleswig-Holstein (2013-2018) ---\n",
    "# This creates a list of public holidays in Schleswig-Holstein for all years in the dataset\n",
    "# These dates are used to identify holidays in the dataset\n",
    "\n",
    "# Fixed holidays (same date every year)\n",
    "def get_fixed_holidays(years):\n",
    "    \"\"\"Generate fixed holidays for given years\"\"\"\n",
    "    fixed = []\n",
    "    for year in years:\n",
    "        fixed.extend([\n",
    "            pd.Timestamp(f'{year}-01-01'),  # New Year's Day\n",
    "            pd.Timestamp(f'{year}-05-01'),  # Labour Day\n",
    "            pd.Timestamp(f'{year}-10-03'),  # German Unity Day\n",
    "            pd.Timestamp(f'{year}-10-31'),  # Reformation Day\n",
    "            pd.Timestamp(f'{year}-11-01'),  # All Saints' Day\n",
    "            pd.Timestamp(f'{year}-12-25'),  # Christmas Day\n",
    "            pd.Timestamp(f'{year}-12-26'),  # Boxing Day\n",
    "        ])\n",
    "    return fixed\n",
    "\n",
    "# Easter-based holidays (moveable dates)\n",
    "# These are calculated based on Easter Sunday\n",
    "easter_dates = {\n",
    "    2013: pd.Timestamp('2013-03-31'),\n",
    "    2014: pd.Timestamp('2014-04-20'),\n",
    "    2015: pd.Timestamp('2015-04-05'),\n",
    "    2016: pd.Timestamp('2016-03-27'),\n",
    "    2017: pd.Timestamp('2017-04-16'),\n",
    "    2018: pd.Timestamp('2018-04-01'),\n",
    "}\n",
    "\n",
    "def get_easter_holidays(easter_dates):\n",
    "    \"\"\"Generate Easter-based holidays from Easter Sunday dates\"\"\"\n",
    "    easter_holidays = []\n",
    "    for year, easter in easter_dates.items():\n",
    "        # Good Friday (2 days before Easter)\n",
    "        easter_holidays.append(easter - pd.Timedelta(days=2))\n",
    "        # Easter Sunday\n",
    "        easter_holidays.append(easter)\n",
    "        # Easter Monday (1 day after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=1))\n",
    "        # Ascension Day (39 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=39))\n",
    "        # Whit Sunday (49 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=49))\n",
    "        # Whit Monday (50 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=50))\n",
    "        # Corpus Christi (60 days after Easter)\n",
    "        easter_holidays.append(easter + pd.Timedelta(days=60))\n",
    "    return easter_holidays\n",
    "\n",
    "# Carnival Tuesday (moveable, 47 days before Easter)\n",
    "carnival_dates = {\n",
    "    2013: pd.Timestamp('2013-02-12'),\n",
    "    2014: pd.Timestamp('2014-03-04'),\n",
    "    2015: pd.Timestamp('2015-02-17'),\n",
    "    2016: pd.Timestamp('2016-02-09'),\n",
    "    2017: pd.Timestamp('2017-02-28'),\n",
    "    2018: pd.Timestamp('2018-02-13'),\n",
    "}\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017, 2018]\n",
    "\n",
    "# Combine all holidays\n",
    "schleswig_holstein_holidays = (\n",
    "    get_fixed_holidays(years) + \n",
    "    get_easter_holidays(easter_dates) + \n",
    "    list(carnival_dates.values())\n",
    ")\n",
    "\n",
    "# Remove duplicates and sort\n",
    "schleswig_holstein_holidays = sorted(list(set(schleswig_holstein_holidays)))\n",
    "\n",
    "print(f\"Defined {len(schleswig_holstein_holidays)} holidays for Schleswig-Holstein (2013-2018)\")\n",
    "print(\"Year distribution:\")\n",
    "for year in years:\n",
    "    holidays_in_year = sum(1 for h in schleswig_holstein_holidays if h.year == year)\n",
    "    print(f\"  {year}: {holidays_in_year} holidays\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9990ef",
   "metadata": {},
   "source": [
    "### Create a function to add a holiday indicator to the merged dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5085cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.840218Z",
     "iopub.status.busy": "2025-11-20T19:28:51.840037Z",
     "iopub.status.idle": "2025-11-20T19:28:51.842745Z",
     "shell.execute_reply": "2025-11-20T19:28:51.842426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holiday indicator function defined successfully\n",
      "This function will add an 'is_holiday' column to the merged dataset\n"
     ]
    }
   ],
   "source": [
    "def add_holiday_indicator(df, holidays, date_column='Datum'):\n",
    "    \"\"\"\n",
    "    Add a holiday indicator column to a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to which the holiday indicator will be added\n",
    "    holidays : list\n",
    "        List of pd.Timestamp objects representing holidays\n",
    "    date_column : str\n",
    "        The name of the date column in the DataFrame (default: 'Datum')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new 'is_holiday' column (1 if holiday, 0 otherwise)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Create a boolean column checking if each date is in the holidays list\n",
    "    df['is_holiday'] = df[date_column].isin(holidays).astype(int)\n",
    "    return df\n",
    "\n",
    "print(\"Holiday indicator function defined successfully\")\n",
    "print(\"This function will add an 'is_holiday' column to the merged dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b433b",
   "metadata": {},
   "source": [
    "# This code merges the given CSV Datasets and can be used to combine new datasets to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a66ea",
   "metadata": {},
   "source": [
    "## Load and Merge Datasets (CAREFUL: This cell creats a new csv file)\n",
    "Now proceed with loading the CSV files and performing the outer join. The holiday indicator will be added after the merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384286d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.844489Z",
     "iopub.status.busy": "2025-11-20T19:28:51.844342Z",
     "iopub.status.idle": "2025-11-20T19:28:51.965640Z",
     "shell.execute_reply": "2025-11-20T19:28:51.965321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../raw_data/umsatzdaten_gekuerzt.csv...\n",
      "Loading ../raw_data/test.csv...\n",
      "Combined umsatz + test: 11164 rows\n",
      "Loading ../raw_data/kiwo.csv...\n",
      "Loading ../raw_data/wetter.csv...\n",
      "Loading ../raw_data/Niederschlag.csv...\n",
      "All files loaded and indexed on 'Datum'.\n",
      "Performing outer join with umsatz+test as base...\n",
      "Added holiday indicator variable to merged dataset\n",
      "\n",
      "--- Join Complete ---\n",
      "First 5 rows of the combined data:\n",
      "       Datum  id  Warengruppe  Umsatz  KielerWoche  Bewoelkung  Temperatur  \\\n",
      "0 2012-01-01 NaN          NaN     NaN          NaN         8.0      9.8250   \n",
      "1 2012-01-02 NaN          NaN     NaN          NaN         7.0      7.4375   \n",
      "2 2012-01-03 NaN          NaN     NaN          NaN         8.0      5.5375   \n",
      "3 2012-01-04 NaN          NaN     NaN          NaN         4.0      5.6875   \n",
      "4 2012-01-05 NaN          NaN     NaN          NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  Niederschlag  is_holiday  \n",
      "0                 14.0        58.0          14.0           0  \n",
      "1                 12.0         NaN           0.0           0  \n",
      "2                 18.0        63.0          20.8           0  \n",
      "3                 19.0        80.0          19.7           0  \n",
      "4                 23.0        80.0           3.3           0  \n",
      "\n",
      "Last 5 rows of the combined data:\n",
      "           Datum  id  Warengruppe  Umsatz  KielerWoche  Bewoelkung  \\\n",
      "11777 2019-12-27 NaN          NaN     NaN          NaN         NaN   \n",
      "11778 2019-12-28 NaN          NaN     NaN          NaN         NaN   \n",
      "11779 2019-12-29 NaN          NaN     NaN          NaN         NaN   \n",
      "11780 2019-12-30 NaN          NaN     NaN          NaN         NaN   \n",
      "11781 2019-12-31 NaN          NaN     NaN          NaN         NaN   \n",
      "\n",
      "       Temperatur  Windgeschwindigkeit  Wettercode  Niederschlag  is_holiday  \n",
      "11777         NaN                  NaN         NaN           0.0           0  \n",
      "11778         NaN                  NaN         NaN           0.0           0  \n",
      "11779         NaN                  NaN         NaN           0.0           0  \n",
      "11780         NaN                  NaN         NaN           0.1           0  \n",
      "11781         NaN                  NaN         NaN           0.0           0  \n",
      "\n",
      "Total rows in combined file: 11782\n",
      "Holidays found in dataset: 294\n",
      "\n",
      "Successfully saved combined data to 'combined_data_outer.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Define File Names (repo-root-relative paths so nbconvert works) ---\n",
    "file_umsatz = '1_DatasetCharacteristics/raw_data/umsatzdaten_gekuerzt.csv'\n",
    "file_test = '1_DatasetCharacteristics/raw_data/test.csv'\n",
    "file_kiwo = '1_DatasetCharacteristics/raw_data/kiwo.csv'\n",
    "file_wetter = '1_DatasetCharacteristics/raw_data/wetter.csv'\n",
    "file_niederschlag = '1_DatasetCharacteristics/raw_data/Niederschlag.csv'\n",
    "\n",
    "try:\n",
    "    # --- 2. Load Umsatz and Test, then concatenate them ---\n",
    "    print(f\"Loading {file_umsatz}...\")\n",
    "    df_umsatz = pd.read_csv(file_umsatz, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_test}...\")\n",
    "    df_test = pd.read_csv(file_test, parse_dates=['Datum'])\n",
    "\n",
    "    # Concatenate Umsatz and test rows first (append test rows to umsatz)\n",
    "    df_umsatz_combined = pd.concat([df_umsatz, df_test], ignore_index=True)\n",
    "    print(f\"Combined umsatz + test: {len(df_umsatz_combined)} rows\")\n",
    "\n",
    "    # --- 3. Load other CSVs ---\n",
    "    print(f\"Loading {file_kiwo}...\")\n",
    "    df_kiwo = pd.read_csv(file_kiwo, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_wetter}...\")\n",
    "    df_wetter = pd.read_csv(file_wetter, parse_dates=['Datum'])\n",
    "\n",
    "    print(f\"Loading {file_niederschlag}...\")\n",
    "    df_niederschlag = pd.read_csv(file_niederschlag, parse_dates=['Datum'])\n",
    "\n",
    "    # --- 4. Set 'Datum' as the Index for All DataFrames ---\n",
    "    df_umsatz_combined = df_umsatz_combined.set_index('Datum')\n",
    "    df_kiwo = df_kiwo.set_index('Datum')\n",
    "    df_wetter = df_wetter.set_index('Datum')\n",
    "    df_niederschlag = df_niederschlag.set_index('Datum')\n",
    "\n",
    "    print(\"All files loaded and indexed on 'Datum'.\")\n",
    "\n",
    "    # --- 5. Perform the Outer Join ---\n",
    "    other_dfs = [df_kiwo, df_wetter, df_niederschlag]\n",
    "    print(\"Performing outer join with umsatz+test as base...\")\n",
    "    final_df = df_umsatz_combined.join(other_dfs, how='outer')\n",
    "\n",
    "    # --- 6. Clean Up and Add Holiday Indicator ---\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df = final_df.sort_values(by='Datum')\n",
    "    final_df = add_holiday_indicator(final_df, schleswig_holstein_holidays, date_column='Datum')\n",
    "    print(\"Added holiday indicator variable to merged dataset\")\n",
    "\n",
    "    # --- 7. Display Results and Save to File ---\n",
    "    print(\"\\n--- Join Complete ---\")\n",
    "    print(\"First 5 rows of the combined data:\")\n",
    "    print(final_df.head())\n",
    "\n",
    "    print(\"\\nLast 5 rows of the combined data:\")\n",
    "    print(final_df.tail())\n",
    "\n",
    "    print(f\"\\nTotal rows in combined file: {len(final_df)}\")\n",
    "    print(f\"Holidays found in dataset: {final_df['is_holiday'].sum()}\")\n",
    "\n",
    "    output_filename = 'combined_data_outer.csv'\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nSuccessfully saved combined data to '{output_filename}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: File not found.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    print(\"Please make sure all CSV files are present in '1_DatasetCharacteristics/raw_data/'.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8fd48",
   "metadata": {},
   "source": [
    "## Merge test.csv to the Dataset\n",
    "Append the test data to the merged dataset for extended coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3a939e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T19:28:51.967303Z",
     "iopub.status.busy": "2025-11-20T19:28:51.967168Z",
     "iopub.status.idle": "2025-11-20T19:28:51.979406Z",
     "shell.execute_reply": "2025-11-20T19:28:51.979076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged file 'combined_data_outer.csv'...\n",
      "Merged file loaded: 11782 rows\n",
      "Date range: 2012-01-01 00:00:00 to 2019-12-31 00:00:00\n",
      "Holidays in merged data: 294\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # The merged file was created in the previous cell: 'combined_data_outer.csv'\n",
    "    output_filename = 'combined_data_outer.csv'\n",
    "    print(f\"Loading merged file '{output_filename}'...\")\n",
    "    df_combined = pd.read_csv(output_filename, parse_dates=['Datum'])\n",
    "    print(f\"Merged file loaded: {len(df_combined)} rows\")\n",
    "    print(\"Date range:\", df_combined['Datum'].min(), \"to\", df_combined['Datum'].max())\n",
    "    if 'is_holiday' in df_combined.columns:\n",
    "        print(f\"Holidays in merged data: {df_combined['is_holiday'].sum()}\")\n",
    "    else:\n",
    "        print(\"Holiday indicator column not present in merged file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading merged file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
